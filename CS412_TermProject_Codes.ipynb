{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4z2Xb7JF/Srs4N96QErdi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melihcgn/Algorithms---HW4/blob/master/CS412_TermProject_Codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "VXXcL749i_G9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmJAAKFOi9h8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Create a pipeline to vectorize the text data and train a Random Forest classifier\n",
        "pipeline = make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = pipeline.predict(X_test)\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "test_data.drop(columns=['summary'], inplace=True)\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_rndforest.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weighted voting / Soft voting"
      ],
      "metadata": {
        "id": "mqfcxCLQjDfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load prediction CSVs from different models\n",
        "bugs_testpredictions_lightgbm_submission = pd.read_csv('bugs-test-predictions-lightgbm-submission.csv')\n",
        "bugs_test_predictions_rf_submission = pd.read_csv('bugs-test-predictions-rf-submission.csv')\n",
        "bugs_test_predictions_logreg_submission = pd.read_csv('bugs-test-predictions-logreg-submission.csv')\n",
        "bugs_test_predictions = pd.read_csv('bugs-test-predictions.csv')\n",
        "bugs_test_predictions_lr = pd.read_csv('bugs-test-predictions_lr.csv')\n",
        "bugs_test_predictions_gradientboost_woutsum = pd.read_csv('bugs-test-predictions_gradientboost_woutsum.csv')\n",
        "test1_predictions_SVM_OvUn = pd.read_csv('test1_predictions_SVM_OvUn.csv')\n",
        "bugs_test_predictions_rndforest = pd.read_csv('bugs-test-predictions_rndforest.csv')\n",
        "predicted_test_data_xgboost_vol2 = pd.read_csv('predicted_test_data_xgboost_vol2.csv')\n",
        "predicted_severities = pd.read_csv('predicted_severities.csv')\n",
        "bugs_test_predictions_mlp_woutsum=pd.read_csv('bugs-test-predictions_mlp_woutsum.csv')\n",
        "final_predictions_with_adaboost_v100 = pd.read_csv('final_predictions_with_adaboost_v100.csv')\n",
        "# Define weights for each model (you can adjust these based on model performance)\n",
        "accuracy_rates = {\n",
        "    'lightgbm': 0.40854,\n",
        "    'rf': 0.35649,\n",
        "    'logreg': 0.42913,\n",
        "    'ayc': 0.49414,\n",
        "    'lr': 0.36980,\n",
        "    'gradientboost': 0.40854,\n",
        "    'rndforest': 0.60637,\n",
        "    'xgboost':0.50713,\n",
        "    'ps':0.49287,\n",
        "    'ada100':0.39476\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Combine dataframes into a list\n",
        "dataframes = [bugs_testpredictions_lightgbm_submission,\n",
        "              bugs_test_predictions_rf_submission,\n",
        "              bugs_test_predictions_logreg_submission,\n",
        "              bugs_test_predictions,\n",
        "              bugs_test_predictions_lr,\n",
        "              bugs_test_predictions_gradientboost_woutsum,\n",
        "              bugs_test_predictions_rndforest,\n",
        "              predicted_test_data_xgboost_vol2,\n",
        "              predicted_severities,\n",
        "              test1_predictions_SVM_OvUn,\n",
        "              bugs_test_predictions_mlp_woutsum,\n",
        "              final_predictions_with_adaboost_v100\n",
        "              ]\n",
        "\n",
        "# Define weights for each model (this list must correspond in order to your dataframe list)\n",
        "weights = [0.40854, 0.35649, 0.42913, 0.49414, 0.36980, 0.40854, 0.60637,0.50713, 0.49287, 0.27333, 0.28, 0.39476]\n",
        "#weights = [1,1,1,1,1,1,1,1,1,1,1,1]\n",
        "\n",
        "# Calculate squared weights\n",
        "#squared_weights = [weight**2 for weight in weights\n",
        "squared_weights = [rate**(1/2) for rate in weights]\n",
        "\n",
        "# Assign weights to each dataframe\n",
        "for df, weight in zip(dataframes, weights):\n",
        "    df['weight'] = weight\n",
        "\n",
        "# Step 3: Concatenate all DataFrames\n",
        "all_data = pd.concat(dataframes)\n",
        "\n",
        "# Step 4: Group by 'bug.id' and 'severity' and sum the weights\n",
        "result = all_data.groupby(['bug_id', 'severity']).sum()\n",
        "\n",
        "# Step 5: Unstack the severity and sum the weights\n",
        "# This transformation puts each severity in its own column with their summed weights\n",
        "result_unstacked = result['weight'].unstack(fill_value=0)\n",
        "\n",
        "# Find the severity with the maximum weighted score for each bug.id\n",
        "final_severity = result_unstacked.idxmax(axis=1)\n",
        "\n",
        "# Create a DataFrame for final results\n",
        "final_results = pd.DataFrame({'bug_id': final_severity.index, 'severity': final_severity.values})\n",
        "\n",
        "# Print or save the results\n",
        "print(final_results)\n",
        "# Optionally save to CSV\n",
        "final_results.to_csv('final_predictions_softVote.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "tmOjKgnujI0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaboost"
      ],
      "metadata": {
        "id": "5Ogov1O0jSx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load prediction CSVs from different models\n",
        "dataframes = {\n",
        "    'lightgbm': pd.read_csv('bugs-test-predictions-lightgbm-submission.csv'),\n",
        "    'rf': pd.read_csv('bugs-test-predictions-rf-submission.csv'),\n",
        "    'logreg': pd.read_csv('bugs-test-predictions-logreg-submission.csv'),\n",
        "    'generic': pd.read_csv('bugs-test-predictions.csv'),\n",
        "    'lr': pd.read_csv('bugs-test-predictions_lr.csv'),\n",
        "    'gradientboost': pd.read_csv('bugs-test-predictions_gradientboost_woutsum.csv'),\n",
        "    'rndforest': pd.read_csv('bugs-test-predictions_rndforest.csv'),\n",
        "    'xgboost': pd.read_csv('predicted_test_data_xgboost_vol2.csv'),\n",
        "    'pred_severities': pd.read_csv('predicted_severities.csv'),\n",
        "    'svm': pd.read_csv('test1_predictions_SVM_OvUn.csv'),\n",
        "    'mlp': pd.read_csv('bugs-test-predictions_mlp_woutsum.csv')\n",
        "}\n",
        "\n",
        "# Prepare the DataFrame with all predictions aligned\n",
        "all_predictions = pd.DataFrame()\n",
        "\n",
        "for name, df in dataframes.items():\n",
        "    df = df.rename(columns={'severity': name})\n",
        "    if all_predictions.empty:\n",
        "        all_predictions = df\n",
        "    else:\n",
        "        all_predictions = pd.merge(all_predictions, df, on='bug_id', how='outer')\n",
        "\n",
        "# Interpolate NaN values (filling missing values)\n",
        "all_predictions = all_predictions.interpolate(method='linear', axis=0)\n",
        "\n",
        "# Convert NaN values to 0 if there are still any\n",
        "all_predictions.fillna(0, inplace=True)\n",
        "\n",
        "# Encode the severities into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "for col in all_predictions.columns:\n",
        "    if col != 'bug_id':  # Avoid encoding bug_id\n",
        "        all_predictions[col] = label_encoder.fit_transform(all_predictions[col])\n",
        "\n",
        "# Initialize AdaBoost\n",
        "ada_boost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Extract features and target\n",
        "X = all_predictions.drop('bug_id', axis=1)\n",
        "y = all_predictions['pred_severities']  # Use 'pred_severities' as the target\n",
        "\n",
        "# Train AdaBoost on the entire dataset\n",
        "ada_boost.fit(X, y)\n",
        "\n",
        "# Predict on the entire dataset\n",
        "y_pred = ada_boost.predict(X)\n",
        "\n",
        "# Convert numeric predictions back to labels\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Create a DataFrame for final results\n",
        "final_results = pd.DataFrame({\n",
        "    'bug_id': all_predictions['bug_id'],\n",
        "    'predicted_severity': y_pred_labels\n",
        "})\n",
        "\n",
        "# Display the results\n",
        "print(final_results)\n",
        "\n",
        "# Optionally save to CSV\n",
        "final_results.to_csv('final_predictions_with_adaboost_v100.csv', index=False)\n"
      ],
      "metadata": {
        "id": "aRnS944UjYOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "AbrmRHW8jbZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Create a pipeline to vectorize the text data and train an MLP classifier\n",
        "pipeline = make_pipeline(TfidfVectorizer(), MLPClassifier(hidden_layer_sizes=(10,), max_iter=10, random_state=42))\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = pipeline.predict(X_test)\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_mlp.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "ulZ0yeHnjrIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "wPIHdjJ2jsHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, average_precision_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Display first few rows of the datasets\n",
        "print(train_data.head())\n",
        "print(test_data.head())\n",
        "\n",
        "# Map severity labels to numerical values\n",
        "severity_mapping = {\n",
        "    'enhancement': 0,\n",
        "    'minor': 1,\n",
        "    'normal': 2,\n",
        "    'major': 3,\n",
        "    'blocker': 4,\n",
        "    'critical': 5\n",
        "}\n",
        "\n",
        "train_data['severity'] = train_data['severity'].map(severity_mapping)\n",
        "\n",
        "# Check for missing values and handle them\n",
        "print(train_data.isnull().sum())\n",
        "train_data = train_data.dropna(subset=['summary', 'severity'])\n",
        "\n",
        "# Preprocess the data\n",
        "X = train_data['summary'] + ' ' + train_data['bug_id'].astype(str)\n",
        "y = train_data['severity']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train_split = vectorizer.fit_transform(X_train_split)\n",
        "X_valid_split = vectorizer.transform(X_valid_split)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logreg_model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on validation set\n",
        "logreg_y_pred = logreg_model.predict(X_valid_split)\n",
        "\n",
        "# Classification report\n",
        "print(\"Logistic Regression Classification Report\")\n",
        "print(classification_report(y_valid_split, logreg_y_pred))\n",
        "\n",
        "# Precision-Recall Curve\n",
        "logreg_y_scores = logreg_model.predict_proba(X_valid_split)\n",
        "logreg_precision = dict()\n",
        "logreg_recall = dict()\n",
        "logreg_average_precision = dict()\n",
        "for i in range(len(severity_mapping)):\n",
        "    logreg_precision[i], logreg_recall[i], _ = precision_recall_curve(y_valid_split == i, logreg_y_scores[:, i])\n",
        "    logreg_average_precision[i] = average_precision_score(y_valid_split == i, logreg_y_scores[:, i])\n",
        "\n",
        "# Plot Precision-Recall curve for Logistic Regression\n",
        "plt.figure(figsize=(10, 7))\n",
        "for i in range(len(severity_mapping)):\n",
        "    plt.plot(logreg_recall[i], logreg_precision[i], lw=2, label=f'Class {i} (area = {logreg_average_precision[i]:0.2f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Logistic Regression Precision-Recall curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Preprocess the test data\n",
        "test_data['text'] = test_data['summary'] + ' ' + test_data['bug_id'].astype(str)\n",
        "X_test = vectorizer.transform(test_data['text'])\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = logreg_model.predict(X_test)\n",
        "\n",
        "# Map numerical severity back to categorical\n",
        "severity_mapping_reverse = {v: k for k, v in severity_mapping.items()}\n",
        "test_data['severity'] = test_predictions\n",
        "test_data['severity'] = test_data['severity'].map(severity_mapping_reverse)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'bug_id': test_data['bug_id'],\n",
        "    'severity': test_data['severity']\n",
        "})\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission.to_csv('bugs-test-predictions-logreg-submission.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to bugs-test-predictions-logreg-submission.csv\")"
      ],
      "metadata": {
        "id": "khgCwHeHkJ66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LİghtGBM"
      ],
      "metadata": {
        "id": "-mx3kShckLGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Assuming the files are named 'bugs-train.csv' and 'bugs-test.csv'\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Display first few rows of the datasets\n",
        "print(train_data.head())\n",
        "print(test_data.head())\n",
        "\n",
        "# Map severity labels to numerical values\n",
        "severity_mapping = {\n",
        "    'enhancement': 1,\n",
        "    'minor': 2,\n",
        "    'normal': 3,\n",
        "    'major': 4,\n",
        "    'blocker': 5,\n",
        "    'critical': 6\n",
        "}\n",
        "\n",
        "train_data['severity'] = train_data['severity'].map(severity_mapping)\n",
        "\n",
        "# Convert 'summary' and 'bug type' to strings and combine them for feature extraction\n",
        "train_data['text'] = train_data['summary'].astype(str) + ' ' + train_data['bug_id'].astype(str)\n",
        "test_data['text'] = test_data['summary'].astype(str) + ' ' + test_data['bug_id'].astype(str)\n",
        "\n",
        "# Remove rows with NaN values in the target variable\n",
        "train_data = train_data.dropna(subset=['severity'])\n",
        "\n",
        "# TF-IDF Vectorization with fewer features\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=2000)\n",
        "X_train = vectorizer.fit_transform(train_data['text'])\n",
        "y_train = train_data['severity']\n",
        "\n",
        "X_test = vectorizer.transform(test_data['text'])\n",
        "\n",
        "# Train-test split for validation\n",
        "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_split, y_train_split)\n",
        "\n",
        "# Define a smaller parameter grid for Randomized Search\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50],\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_child_samples': [20, 50]\n",
        "}\n",
        "\n",
        "# Initialize the LightGBM model with force_col_wise parameter to avoid threading issues\n",
        "lgb_model = lgb.LGBMClassifier(random_state=42, force_col_wise=True, verbose=2)\n",
        "\n",
        "# Perform Randomized Search with fewer iterations\n",
        "random_search = RandomizedSearchCV(estimator=lgb_model, param_distributions=param_grid, cv=3, n_iter=10, scoring='precision_macro', random_state=42, n_jobs=1)\n",
        "random_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best parameters found by Randomized Search:\", best_params)\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_lgb_model = lgb.LGBMClassifier(**best_params, random_state=42, force_col_wise=True, verbose=2)\n",
        "best_lgb_model.fit(\n",
        "    X_train_res, y_train_res,\n",
        "    eval_set=[(X_valid_split, y_valid_split)],\n",
        "    eval_metric='logloss',\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10)]\n",
        ")\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred = best_lgb_model.predict(X_valid_split)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_valid_split, y_pred))\n",
        "\n",
        "# Precision-Recall Curve\n",
        "y_scores = best_lgb_model.predict_proba(X_valid_split)\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "average_precision = dict()\n",
        "for i in range(len(severity_mapping)):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(y_valid_split == i+1, y_scores[:, i])\n",
        "    average_precision[i] = average_precision_score(y_valid_split == i+1, y_scores[:, i])\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(10, 7))\n",
        "for i in range(len(severity_mapping)):\n",
        "    plt.plot(recall[i], precision[i], lw=2, label=f'Class {i+1} (area = {average_precision[i]:0.2f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('LightGBM Precision-Recall curve with Best Params')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# Predict on test set\n",
        "test_pred = best_lgb_model.predict(X_test)\n",
        "test_data['severity'] = test_pred\n",
        "\n",
        "# Map numerical severity back to categorical\n",
        "severity_mapping_reverse = {\n",
        "    1: 'enhancement',\n",
        "    2: 'minor',\n",
        "    3: 'normal',\n",
        "    4: 'major',\n",
        "    5: 'blocker',\n",
        "    6: 'critical'\n",
        "}\n",
        "\n",
        "# Convert the numerical severity back to categorical\n",
        "test_data['severity'] = test_data['severity'].map(severity_mapping_reverse)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'bug_id': test_data['bug_id'],\n",
        "    'severity': test_data['severity']\n",
        "})\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission.to_csv('bugs-test-predictions-lightgbm-submission.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to bugs-test-predictions-lightgbm-submission.csv\")"
      ],
      "metadata": {
        "id": "RX5pg1EwkRf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boost"
      ],
      "metadata": {
        "id": "gZhjFEKskj8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Create a pipeline to vectorize the text data and train a Gradient Boosting classifier\n",
        "pipeline = make_pipeline(TfidfVectorizer(), GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = pipeline.predict(X_test)\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_gradientboost.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "aJPA-NGBkr44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Soft Voting (Logistic regression + random forest)\n",
        "\n",
        "> Blok alıntı ekle\n",
        "\n"
      ],
      "metadata": {
        "id": "VXhWStG9ksuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Load the training data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "# Combine summary and bug_id into a single feature (optional)\n",
        "train_data['text'] = train_data['bug_id'].astype(str) + ' ' + train_data['summary']\n",
        "test_data['text'] = test_data['bug_id'].astype(str) + ' ' + test_data['summary']\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['severity_encoded'] = label_encoder.fit_transform(train_data['severity'])\n",
        "\n",
        "# Define the feature and target variable\n",
        "X_train = train_data['text']\n",
        "y_train = train_data['severity_encoded']\n",
        "X_test = test_data['text']\n",
        "\n",
        "# Create pipelines for both classifiers\n",
        "pipeline_lr = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "pipeline_rf = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Create a voting classifier with weighted voting\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', pipeline_lr), ('rf', pipeline_rf)],\n",
        "    voting='soft',\n",
        "    weights=[1, 2]  # Assign weights to the classifiers\n",
        ")\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the severity for the test data\n",
        "predictions = voting_clf.predict(X_test)\n",
        "\n",
        "# Decode the predicted labels\n",
        "predicted_severities = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Add predictions to the test data\n",
        "test_data['severity'] = predicted_severities\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "test_data[['bug_id', 'severity']].to_csv('predicted_severities.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predicted_severities.csv'\")"
      ],
      "metadata": {
        "id": "ox7dISvrk391"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hard Voting (Logistic regression + random forest + Gradient Boosting)"
      ],
      "metadata": {
        "id": "-7OpMFVNlJtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Transform the training and validation data\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_split)\n",
        "X_val_tfidf = tfidf.transform(X_val_split)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Define base models\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the stacking classifier\n",
        "estimators = [\n",
        "    ('log_reg', log_reg),\n",
        "    ('rf', rf),\n",
        "    ('gb', gb)\n",
        "]\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000, random_state=42)\n",
        ")\n",
        "\n",
        "# Train the stacking classifier\n",
        "stacking_clf.fit(X_train_tfidf, y_train_split)\n",
        "\n",
        "# Validate the model\n",
        "y_val_pred = stacking_clf.predict(X_val_tfidf)\n",
        "print(classification_report(y_val_split, y_val_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Train the stacking classifier on the full training data\n",
        "X_train_full_tfidf = tfidf.fit_transform(X_train)\n",
        "stacking_clf.fit(X_train_full_tfidf, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = []\n",
        "\n",
        "# Initialize tqdm for progress bar\n",
        "with tqdm(total=len(X_test), desc=\"Processing\", mininterval=0.1) as progress_bar:\n",
        "    for text in X_test:\n",
        "        encoded_pred = stacking_clf.predict([text])\n",
        "        y_test_pred_encoded.append(encoded_pred[0])\n",
        "        progress_bar.update(1)  # Update progress bar\n",
        "\n",
        "# Decode the predictions\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "\n",
        "# Delete the \"summary\" column\n",
        "test_data.drop(columns=['summary'], inplace=True)\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_hardVoting.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "ltR1MG4ylKBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM USİNG oversampling (with SMOTE) and undersampling (with Nearmiss)"
      ],
      "metadata": {
        "id": "u1VV-M7GyCgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Define preprocess_text function if not already defined\n",
        "def preprocess_text(text):\n",
        "    # Placeholder preprocessing function, replace with your actual preprocessing logic\n",
        "    return text.lower()\n",
        "\n",
        "# Load training data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test1_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Apply preprocessing\n",
        "train_data['summary_clean'] = train_data['summary'].apply(preprocess_text)\n",
        "test1_data['summary_clean'] = test1_data['summary'].apply(preprocess_text)\n",
        "\n",
        "# Vectorize the text data\n",
        "tfidf = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = tfidf.fit_transform(train_data['summary_clean'])\n",
        "X_test1_tfidf = tfidf.transform(test1_data['summary_clean'])\n",
        "\n",
        "# Apply NearMiss undersampling to the majority class\n",
        "nm1 = NearMiss(version=1)\n",
        "X_undersampled, y_undersampled = nm1.fit_resample(X_train_tfidf, train_data['severity'])\n",
        "\n",
        "# Apply SMOTE oversampling to the undersampled data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_undersampled, y_undersampled)\n",
        "\n",
        "# Divide the resampled data into train and validation sets\n",
        "X_train_resampled, X_validation, y_train_resampled, y_validation = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train SVM model with the best parameters\n",
        "best_svm = SVC(C=1, gamma=0.01, kernel='linear', probability=True)\n",
        "best_svm.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict severity labels for validation data\n",
        "y_pred_validation = best_svm.predict(X_validation)\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "precision = precision_score(y_validation, y_pred_validation, average='weighted')\n",
        "recall = recall_score(y_validation, y_pred_validation, average='weighted')\n",
        "f1 = f1_score(y_validation, y_pred_validation, average='weighted')\n",
        "accuracy = accuracy_score(y_validation, y_pred_validation)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Predict severity labels for test data\n",
        "test_predictions = best_svm.predict(X_test1_tfidf)\n",
        "\n",
        "# Create a DataFrame with bug_id and predicted severity\n",
        "final_predictions = pd.DataFrame({\n",
        "    'bug_id': test1_data['bug_id'],\n",
        "    'severity': test_predictions\n",
        "})\n",
        "\n",
        "# Save the final predictions to a CSV file\n",
        "final_predictions.to_csv('final_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0PkDJu2x__2",
        "outputId": "86959baa-871c-483d-a38b-c722856c5b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5671602064209946\n",
            "Recall: 0.5647921760391198\n",
            "F1-Score: 0.5641976945045722\n",
            "Accuracy: 0.5647921760391198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xgboost"
      ],
      "metadata": {
        "id": "WEw1Cn3uLCIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "severity_mapping = {\n",
        "    'enhancement': 0,\n",
        "    'minor': 1,\n",
        "    'normal': 2,\n",
        "    'major': 3,\n",
        "    'blocker': 4,\n",
        "    'critical': 5\n",
        "}\n",
        "\n",
        "train_data['severity'] = train_data['severity'].map(severity_mapping)\n",
        "\n",
        "# Remove rows with missing severity values\n",
        "train_data_clean = train_data.dropna(subset=['severity'])\n",
        "\n",
        "print(train_data_clean.head())\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
        "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n",
        "])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data_clean['summary'], train_data_clean['severity'], test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "evaluation_report = classification_report(y_val, y_pred, target_names=list(severity_mapping.keys()), output_dict=True)\n",
        "\n",
        "# Print evaluation report\n",
        "print(evaluation_report)\n",
        "\n",
        "test_data['severity'] = pipeline.predict(test_data['summary'])\n",
        "test_data['severity'] = test_data['severity'].map({v: k for k, v in severity_mapping.items()})\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "predicted_test_data = test_data[['bug_id', 'summary', 'severity']]\n",
        "predicted_test_data.to_csv('predicted_test_data_xgboost.csv', index=False)"
      ],
      "metadata": {
        "id": "5xADuRoSwfST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}